# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QymPzapxRIeLwDM8SejlZpdO6BVQDQu2

**Loading Packages and Data**
"""

import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

from sklearn.linear_model import LinearRegression

from sklearn.linear_model import Ridge

from sklearn.ensemble import RandomForestRegressor

from xgboost import XGBRegressor

from sklearn.metrics import mean_squared_error

"""**Loading the dataset**"""

from google.colab import drive
drive.mount('/content/drive')

test = pd.read_csv('/content/drive/MyDrive/Technocolabs Mini Project/Test.csv')
train = pd.read_csv('/content/drive/MyDrive/Technocolabs Mini Project/Train.csv')

train['source']='train'
test['source']='test'
data = pd.concat([train, test],ignore_index=True)
# concat() is useful for merging and analyzing datasets with similar structures.

""" **Data Structure and Content**"""

data.head()

data.tail()

data.describe()

data.shape

data.info()

"""**Exploratory Data Analysis (EDA)**

Distribution of variables, identify missing values and detect potential outliers.
"""

# Checking missing values
data.isnull().sum()

"""**Handling Missing Values**

Handle missing values by imputation or deletion depending on the nature of the missingness and the importance of the variable.
"""

#Impute missing values using mean or median for numerical variables
data['Item_Weight'].fillna(data['Item_Weight'].mean(), inplace=True)
data['Item_Outlet_Sales'].fillna(data['Item_Outlet_Sales'].mean(), inplace=True)

data.isnull().sum()

# Create a new category for missing values ('Unknown')
data['Outlet_Size'].fillna('Unknown', inplace=True)

data.isnull().sum()

"""**Univariate analysis**

Univariate analysis explores each variable in a data set, separately.
"""

# Univariate analysis
data.hist(figsize=(10, 10))
plt.show()

"""**Bivariate analysis**

Bivariate analysis is an analysis of two variables to determine the relationships between them.
"""

# Bivariate analysis
plt.scatter(data['Item_Identifier'], data['Item_MRP'])
plt.xlabel('Item_Identifier')
plt.ylabel('Item_MRP')
plt.title('Scatter Plot of Item_Identifier and Item_MRP')
plt.show()

plt.scatter(data['Item_Type'], data['Item_MRP'])
plt.xlabel('Item_Type')
plt.ylabel('Item_MRP')
plt.title('Scatter Plot of Item_Type and Item_MRP')
plt.show()

"""**Feature Engineering**

Feature engineering or feature extraction or feature discovery is the process of extracting features from raw data.
"""

# Create a new feature indicating whether a product is in high demand
#The values in the High_Demand column is 1 if the corresponding value in the Item_Visibility column is greater than 0.5, and 0 otherwise.
data['High_Demand'] = (data['Item_Visibility'] > 0.5) * 1

data['High_Demand']

data.info()

"""**Encoding Categorical Variables**

Encoding categorical data is a process of converting categorical data into integer format so that the data with converted categorical values can be provided to the models to give and improve the predictions.

**One-Hot Encoding -**
One-Hot Encoding is the Most Common method for encoding Categorical variables. a Binary Column is created for each Unique Category in the variable. If a category is present in a sample, the corresponding column is set to 1, and all other columns are set to 0.
"""

# One-hot encode 'Item_Category'
item_type = pd.get_dummies(data['Item_Type'], prefix='Item_Type')
data = pd.concat([data, item_type], axis=1)
data.info()

"""**label encoding -**
label encoding is to assign a unique integer to each category in a categorical variable.

`For example,` if we have a categorical variable “colour” with categories “red”, “green”, and “blue”, we can assign the labels 0, 1, and 2 respectively.
"""

# Label encode 'Outlet_Identifier'
"""data['Outlet_Identifier'] = data['Outlet_Identifier'].astype('category')
data['Outlet_Identifier_Encoded'] = data['Outlet_Identifier'].cat.codes"""

object_columns = data.select_dtypes(include=['object']).columns
from sklearn.preprocessing import LabelEncoder
for column in object_columns:
    encoder = LabelEncoder()
    data[column] = encoder.fit_transform(data[column])

data.info()

data.head(15)

"""**Feature Scaling-**
It is a technique to standardize the independent variables of the dataset in a specific range.
StandardScaler is a class in the scikit-learn library that is used to standardize numerical features.This process ensures that all of the numerical features have a mean of 0 and a standard deviation of 1.
"""

# Standardize numerical variables using StandardScaler
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
numerical_features = ['Item_Weight', 'Item_Visibility', 'Item_MRP']
data[numerical_features] = scaler.fit_transform(data[numerical_features])

data[numerical_features]

"""**Training and Test Set Split**"""

X = data.drop('Item_Outlet_Sales', axis=1)
y = data['Item_Outlet_Sales']

x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

data.isnull().sum()

data.info()

"""**Modeling**"""

lr_model = LinearRegression()
lr_model.fit(x_train, y_train)

lr_train_score=lr_model.score(x_train, y_train)
lr_test_score=lr_model.score(x_test, y_test)
lr_predictions = lr_model.predict(x_test)
print("Linear Regression\n")
print("Train Score - ",lr_train_score,"\nTest Score - ",lr_test_score)
lr_mse = mean_squared_error(y_test,lr_predictions)
print("Mean Square Error:",lr_mse)

ridge_model = Ridge()
ridge_model.fit(x_train, y_train)

ridge_train_score=ridge_model.score(x_train, y_train)
ridge_test_score=ridge_model.score(x_test, y_test)
ridge_predictions =ridge_model.predict(x_test)
print("Ridge Model\n")
print("Train Score - ",ridge_train_score,"\nTest Score - ",ridge_test_score)
ridge_mse = mean_squared_error(y_test,ridge_predictions)
print("Mean Square Error:",ridge_mse)

rf_model = RandomForestRegressor()
rf_model.fit(x_train, y_train)

rf_train_score=rf_model.score(x_train, y_train)
rf_test_score=rf_model.score(x_test, y_test)
rf_predictions =rf_model.predict(x_test)
print("Random Forest Regressor \n")
print("Train Score - ",rf_train_score,"\nTest Score - ",rf_test_score)
rf_mse = mean_squared_error(y_test,rf_predictions)
print("Mean Square Error:",rf_mse)

xgb_model = XGBRegressor()
xgb_model.fit(x_train, y_train)

xgb_train_score=xgb_model.score(x_train, y_train)
xgb_test_score=xgb_model.score(x_test, y_test)
xgb_predictions =xgb_model.predict(x_test)
print("XGB Regressor \n")
print("Train Score - ",xgb_train_score,"\nTest Score - ",xgb_test_score)
xgb_mse = mean_squared_error(y_test,xgb_predictions)
print("Mean Square Error:",xgb_mse)